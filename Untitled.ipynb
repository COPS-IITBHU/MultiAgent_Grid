{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym \n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "import pygame\n",
    "from pygame.locals import(QUIT,KEYDOWN,K_ESCAPE)\n",
    "\n",
    "import Box2D\n",
    "from Box2D.Box2D import b2PolygonShape\n",
    "from Box2D import (b2World, b2CircleShape, b2EdgeShape, b2FixtureDef, b2PolygonShape, b2ContactListener,\n",
    "                   b2Transform, b2Mul, b2Vec2,\n",
    "                   b2_pi)\n",
    "#from Box2D.b2 import (world,polygonShape,circleShape,staticBody,dynamicBody,vec2)\n",
    "from Box2D.b2 import (\n",
    "    world,\n",
    "    edgeShape,\n",
    "    circleShape,\n",
    "    fixtureDef,\n",
    "    polygonShape,\n",
    "    revoluteJointDef,\n",
    "    contactListener,\n",
    ")\n",
    "\n",
    "show_animation = True\n",
    "epsilon=0.01\n",
    "n_points=500\n",
    "scalar_force=0.005\n",
    "class grid(gym.Env):\n",
    "   \n",
    "    \n",
    "    metadata={'render.modes':['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_agents = 8\n",
    "        self.radius = 2 * 0.0254\n",
    "        self.density = 1.0\n",
    "        self.restitution = 0\n",
    "        self.fps = 50\n",
    "        self.sfr = 1\n",
    "        self.screen_height = 600\n",
    "        self.screen_width = 800\n",
    "        self.viewer = None\n",
    "        self.ppm = 240\n",
    "        self.velocity=0.2\n",
    "        self.path=np.zeros(shape=(self.num_agents,n_points,2))\n",
    "\n",
    "        self.time_step = 1./self.fps*self.sfr\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        def draw_line(line, body, fixture):\n",
    "\n",
    "            shape = fixture.shape         \n",
    "            vertices = [(body.transform * v+b2Vec2(1.7,1.25)) * self.ppm for v in shape.vertices]          \n",
    "            vertices = [(v[0], self.screen_height - v[1]) for v in vertices]\n",
    "            pygame.draw.line(self.screen, (\t57, 255, 20,255),vertices[0],vertices[1],width=1)\n",
    "\n",
    "        edgeShape.draw = draw_line\n",
    "\n",
    "        def draw_agents(circle, body, fixture):\n",
    "            position = (body.transform * circle.pos +b2Vec2(1.7,1.25) ) * self.ppm\n",
    "            position = (position[0], self.screen_height - position[1])\n",
    "            pygame.draw.circle(self.screen,(255,255,255,255) , [int(\n",
    "            x) for x in position], int(circle.radius * self.ppm))\n",
    "\n",
    "        circleShape.draw =draw_agents\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "\n",
    "        running = True\n",
    "        steps=0\n",
    "        while running:\n",
    "\n",
    "            '''for event in pygame.event.get():\n",
    "                if event.type == QUIT or (event.type == KEYDOWN and event.key == K_ESCAPE):\n",
    "                # The user closed the window or pressed escape\n",
    "                    running = False'''\n",
    "\n",
    "            self.obs = []\n",
    "            for i in range(0,self.num_agents):\n",
    "                f = self.agents[i].GetWorldVector(localVector=action[i])\n",
    "                p = self.agents[i].GetWorldPoint(localPoint=(0.0 , 0.0))\n",
    "                self.agents[i].ApplyForce(f, p, True)\n",
    "                self.obs.append([self.agents[i].position[0],self.agents[i].position[1],self.agents[i].linearVelocity[0],self.agents[i].linearVelocity[1]])\n",
    "                \n",
    "            \n",
    "            print(self.obs)\n",
    "            print('_________________________________')\n",
    "              \n",
    "\n",
    "            self.world.Step(self.time_step,10,10)\n",
    "            if steps%self.sfr == 0:\n",
    "                self.render() \n",
    "            steps = (steps+1)\n",
    "            if steps*self.time_step > 30:\n",
    "                raise RuntimeError(\"environment timestep exceeded 30 seconds\")\n",
    "\n",
    "            \n",
    "\n",
    "           \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.screen=None\n",
    "        self.world = world(gravity=(0,0))\n",
    "\n",
    "        self.walls()\n",
    "        # Initial position of bots\n",
    "        self.initial_pos=[(7.5*6*0.0254, 1.5*6*0.0254),(-7.5*6*0.0254, 1.5*6*0.0254),(7.5*6*0.0254, -1.5*6*0.0254),(-7.5*6*0.0254, -1.5*6*0.0254),\n",
    "                            (6.5*6*0.0254, 2.5*6*0.0254),(-6.5*6*0.0254, 2.5*6*0.0254),(6.5*6*0.0254, -2.5*6*0.0254),(-6.5*6*0.0254, -2.5*6*0.0254)]\n",
    "\n",
    "        # deploy bots\n",
    "        self.body1 = self.world.CreateDynamicBody(position=self.initial_pos[0], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "        self.body2 = self.world.CreateDynamicBody(position=self.initial_pos[1], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "        self.body0 = self.world.CreateDynamicBody(position=self.initial_pos[2], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "        self.body3 = self.world.CreateDynamicBody(position=self.initial_pos[3], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "        self.body4 = self.world.CreateDynamicBody(position=self.initial_pos[4], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "        self.body5 = self.world.CreateDynamicBody(position=self.initial_pos[5], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "        self.body6 = self.world.CreateDynamicBody(position=self.initial_pos[6], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "        self.body7 = self.world.CreateDynamicBody(position=self.initial_pos[7], fixtures=b2FixtureDef(shape=b2CircleShape(radius=self.radius), density=self.density, restitution=self.restitution))\n",
    "\n",
    "        self.body7.linearVelocity = (1,0)\n",
    "\n",
    "        self.agents=[self.body0,self.body1,self.body2,self.body3,self.body4,self.body5,self.body6,self.body7]\n",
    "        self.reward=0\n",
    "        self.collide=[0]*self.num_agents\n",
    "        self.world.gravity=(0,0)\n",
    "\n",
    "    def walls(self):\n",
    "        # upper lower wall\n",
    "        ground = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, 7*6*0.0254 ), (7*6*0.0254, 7*6*0.0254)])\n",
    "        )\n",
    "        ground1 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, -7*6*0.0254 ), (7*6*0.0254, -7*6*0.0254)])\n",
    "        )\n",
    "        # middle\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, 1*6*0.0254 ), (1*6*0.0254, 1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, -1*6*0.0254 ), (1*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(1*6*0.0254, 1*6*0.0254 ), (1*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, 1*6*0.0254 ), (-1*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        # middle top\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, 5*6*0.0254 ), (1*6*0.0254, 5*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, 3*6*0.0254 ), (1*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(1*6*0.0254, 5*6*0.0254 ), (1*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, 5*6*0.0254 ), (-1*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "        # middle low\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, -5*6*0.0254 ), (1*6*0.0254, -5*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, -3*6*0.0254 ), (1*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(1*6*0.0254, -5*6*0.0254 ), (1*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-1*6*0.0254, -5*6*0.0254 ), (-1*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        # right left\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, 1*6*0.0254 ), (5*6*0.0254, 1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, -1*6*0.0254 ), (5*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, 1*6*0.0254 ), (3*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(5*6*0.0254, 1*6*0.0254 ), (5*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, 1*6*0.0254 ), (-5*6*0.0254, 1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, -1*6*0.0254 ), (-5*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, 1*6*0.0254 ), (-3*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-5*6*0.0254, 1*6*0.0254 ), (-5*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        # corner\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, 5*6*0.0254 ), (5*6*0.0254, 5*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, 3*6*0.0254 ), (5*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, 5*6*0.0254 ), (3*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(5*6*0.0254, 5*6*0.0254 ), (5*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, 5*6*0.0254 ), (-5*6*0.0254, 5*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, 3*6*0.0254 ), (-5*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, 5*6*0.0254 ), (-3*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-5*6*0.0254, 5*6*0.0254 ), (-5*6*0.0254, 3*6*0.0254)])\n",
    "        )\n",
    "\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, -5*6*0.0254 ), (5*6*0.0254, -5*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, -3*6*0.0254 ), (5*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(3*6*0.0254, -5*6*0.0254 ), (3*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(5*6*0.0254, -5*6*0.0254 ), (5*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, -5*6*0.0254 ), (-5*6*0.0254, -5*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, -3*6*0.0254 ), (-5*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-3*6*0.0254, -5*6*0.0254 ), (-3*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-5*6*0.0254, -5*6*0.0254 ), (-5*6*0.0254, -3*6*0.0254)])\n",
    "        )\n",
    "        # side wall\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(7*6*0.0254, 7*6*0.0254 ), (7*6*0.0254, 2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, 7*6*0.0254 ), (-7*6*0.0254, 2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(7*6*0.0254, -7*6*0.0254 ), (7*6*0.0254, -2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, -7*6*0.0254 ), (-7*6*0.0254, -2*6*0.0254)])\n",
    "        )\n",
    "\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(7*6*0.0254, 1*6*0.0254 ), (7*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, 1*6*0.0254 ), (-7*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        # chute\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(8*6*0.0254, 1*6*0.0254 ), (8*6*0.0254, 2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-8*6*0.0254, 1*6*0.0254 ), (-8*6*0.0254, 2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(8*6*0.0254, -1*6*0.0254 ), (8*6*0.0254, -2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-8*6*0.0254, -1*6*0.0254 ), (-8*6*0.0254, -2*6*0.0254)])\n",
    "        )\n",
    "\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(7*6*0.0254, 1*6*0.0254 ), (8*6*0.0254, 1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, 1*6*0.0254 ), (-8*6*0.0254, 1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(7*6*0.0254, -1*6*0.0254 ), (8*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, -1*6*0.0254 ), (-8*6*0.0254, -1*6*0.0254)])\n",
    "        )\n",
    "\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(7*6*0.0254, 2*6*0.0254 ), (8*6*0.0254, 2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, 2*6*0.0254 ), (-8*6*0.0254, 2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(7*6*0.0254, -2*6*0.0254 ), (8*6*0.0254, -2*6*0.0254)])\n",
    "        )\n",
    "        ground3 = self.world.CreateStaticBody(\n",
    "            shapes=b2EdgeShape(vertices=[(-7*6*0.0254, -2*6*0.0254 ), (-8*6*0.0254, -2*6*0.0254)])\n",
    "        )\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    def calc_4points_bezier_path(self, sx, sy, ex, ey,control_points, offset):\n",
    "\n",
    "        dist = np.hypot(sx - ex, sy - ey) / offset\n",
    "        # control_points = np.array(\n",
    "        #     [[sx, sy],\n",
    "        #      [sx + dist * np.cos(syaw), sy + dist * np.sin(syaw)],\n",
    "        #      [ex - dist * np.cos(eyaw), ey - dist * np.sin(eyaw)],\n",
    "        #      [ex, ey]])\n",
    "        # control_points = np.array(\n",
    "        #         [[sx,sy],\n",
    "        #         [3,-3],\n",
    "        #         [4,5],\n",
    "        #         [5,10],\n",
    "        #         [ex,ey]])\n",
    "\n",
    "        path = self.calc_bezier_path(control_points, n_points=500)\n",
    "\n",
    "        return path, control_points\n",
    "\n",
    "\n",
    "    def calc_bezier_path(self, control_points, n_points=500):\n",
    "        \"\"\"\n",
    "        Compute bezier path (trajectory) given control points.\n",
    "\n",
    "        :param control_points: (numpy array)\n",
    "        :param n_points: (int) number of points in the trajectory\n",
    "        :return: (numpy array)\n",
    "        \"\"\"\n",
    "        traj = []\n",
    "        for t in np.linspace(0, 1, n_points):\n",
    "            traj.append(self.bezier(t, control_points))\n",
    "\n",
    "        return np.array(traj)\n",
    "\n",
    "\n",
    "    def bernstein_poly(self, n, i, t):\n",
    "        \"\"\"\n",
    "        Bernstein polynom.\n",
    "\n",
    "        :param n: (int) polynom degree\n",
    "        :param i: (int)\n",
    "        :param t: (float)\n",
    "        :return: (float)\n",
    "        \"\"\"\n",
    "        return scipy.special.comb(n, i) * t ** i * (1 - t) ** (n - i)\n",
    "\n",
    "\n",
    "    def bezier(self, t, control_points):\n",
    "        \"\"\"\n",
    "        Return one point on the bezier curve.\n",
    "\n",
    "        :param t: (float) number in [0, 1]\n",
    "        :param control_points: (numpy array)\n",
    "        :return: (numpy array) Coordinates of the point\n",
    "        \"\"\"\n",
    "        n = len(control_points) - 1\n",
    "        return np.sum([self.bernstein_poly(n, i, t) * control_points[i] for i in range(n + 1)], axis=0)\n",
    "\n",
    "\n",
    "    def bezier_derivatives_control_points(self, control_points, n_derivatives):\n",
    "        \"\"\"\n",
    "        Compute control points of the successive derivatives of a given bezier curve.\n",
    "\n",
    "        A derivative of a bezier curve is a bezier curve.\n",
    "        See https://pomax.github.io/bezierinfo/#derivatives\n",
    "        for detailed explanations\n",
    "\n",
    "        :param control_points: (numpy array)\n",
    "        :param n_derivatives: (int)\n",
    "        e.g., n_derivatives=2 -> compute control points for first and second derivatives\n",
    "        :return: ([numpy array])\n",
    "        \"\"\"\n",
    "        w = {0: control_points}\n",
    "        for i in range(n_derivatives):\n",
    "            n = len(w[i])\n",
    "            w[i + 1] = np.array([(n - 1) * (w[i][j + 1] - w[i][j])\n",
    "                                for j in range(n - 1)])\n",
    "        return w\n",
    "\n",
    "\n",
    "    def curvature(self, dx, dy, ddx, ddy):\n",
    "        \"\"\"\n",
    "        Compute curvature at one point given first and second derivatives.\n",
    "\n",
    "        :param dx: (float) First derivative along x axis\n",
    "        :param dy: (float)\n",
    "        :param ddx: (float) Second derivative along x axis\n",
    "        :param ddy: (float)\n",
    "        :return: (float)\n",
    "        \"\"\"\n",
    "        return (dx * ddy - dy * ddx) / (dx ** 2 + dy ** 2) ** (3 / 2)\n",
    "\n",
    "\n",
    "    def bezier_path(self, start_x, start_y, end_x, end_y, control_points):\n",
    "        \"\"\"Show the effect of the offset.\"\"\"\n",
    "        start_x = 100.0  # [m]\n",
    "        start_y = 10.0  # [m]\n",
    "        start_yaw = np.radians(180.0)  # [rad]\n",
    "\n",
    "        end_x = -0.0  # [m]\n",
    "        end_y = 2.0  # [m]\n",
    "        end_yaw = np.radians(-45.0)  # [rad]\n",
    "\n",
    "        for offset in np.arange(1.0, 5.0, 1.0):\n",
    "            path, control_points = self.calc_4points_bezier_path(\n",
    "                start_x, start_y, end_x, end_y, control_points, offset)\n",
    "            assert path.T[0][0] == start_x, \"path is invalid\"\n",
    "            assert path.T[1][0] == start_y, \"path is invalid\"\n",
    "            assert path.T[0][-1] == end_x, \"path is invalid\"\n",
    "            assert path.T[1][-1] == end_y, \"path is invalid\"\n",
    "\n",
    "            if show_animation:  # pragma: no cover\n",
    "                plt.plot(path.T[0], path.T[1], label=\"Offset=\" + str(offset))\n",
    "\n",
    "        if show_animation:  # pragma: no cover\n",
    "            # self.plot_arrow(start_x, start_y, start_yaw)\n",
    "            # self.plot_arrow(end_x, end_y, end_yaw)\n",
    "            plt.legend()\n",
    "            plt.axis(\"equal\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        print(path)\n",
    "        return path\n",
    "\n",
    "\n",
    "    def update_path(self,index,new_target):\n",
    "\n",
    "        # get bezier points here\n",
    "        new_path=self.bezier_path(self.path[index,n_points-1,0],self.path[index,n_points-1,1],new_target[0],new_target[1], control_points)\n",
    "\n",
    "        self.path[index,:,:]=new_path[:,:]\n",
    "   \n",
    "\n",
    "    def render(self, mode='human',close=False):\n",
    "        if self.screen is None:\n",
    "            self.screen = pygame.display.set_mode((self.screen_width,self.screen_height),0,32)\n",
    "            pygame.display.set_caption('grid-2D')\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.screen.fill((0,0,0,0))\n",
    "\n",
    "        for body in self.world.bodies:\n",
    "            for fixture in body.fixtures:\n",
    "                fixture.shape.draw(body,fixture)\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(self.fps)\n",
    "\n",
    "    def step(self):\n",
    "\n",
    "        for i in range(0,self.num_agents):\n",
    "            for t in self.path[i]:\n",
    "                if ((t[0]-self.path[i,n_points-1,0])**2 + (t[1]-self.path[i,n_points-1,1])**2 < epsilon**2):\n",
    "\n",
    "                    # keep update new target here\n",
    "                    self.update_path(i,new_target) \n",
    "\n",
    "                elif((t[0]-self.agents[i].position[0])**2 + (t[1]-self.agents[i].position[1])**2 > epsilon**2):\n",
    "                    dis=sqrt((t[0]-self.agents[i].position[0])**2 + (t[1]-self.agents[i].position[1])**2)\n",
    "\n",
    "                    f = self.agents[i].GetWorldVector(localVector=((t[0]-self.agents[i].position[0])/dis,(t[1]-self.agents[i].position[1])/dis))\n",
    "                    p = self.agents[i].GetWorldPoint(localPoint=(0.0, 0.00))\n",
    "                    self.agents[i].ApplyForce(f, p, True)\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     env=grid()\n",
    "#     env.reset()\n",
    "#    env.bezier_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.9144, 0.9144), (-0.6095999999999999, 0.9144), (-0.30479999999999996, 0.9144), (0.0, 0.9144), (0.30479999999999996, 0.9144), (0.6095999999999999, 0.9144), (0.9144, 0.9144)]\n"
     ]
    }
   ],
   "source": [
    "print([((-36 +12*i)*0.0254,36*0.0254) for i in range(7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-a7f7f289ae6d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-a7f7f289ae6d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print([((-36 + 12 * i) * 0.0254, 36 * 0.0254) for i in range(7),((-36 + 24 * i) * 0.0254, 24 * 0.0254) for i in range(4)]\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print([((-36 + 12 * i) * 0.0254, 36 * 0.0254) for i in range(7),((-36 + 24 * i) * 0.0254, 24 * 0.0254) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.9144, 0.6095999999999999), (-0.30479999999999996, 0.6095999999999999), (0.30479999999999996, 0.6095999999999999), (0.9144, 0.6095999999999999)]\n"
     ]
    }
   ],
   "source": [
    "print([((-36 + 24 * i) * 0.0254, 24 * 0.0254) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33  5 24 11  3  5 24 21]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.choice(40,8,replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00441377]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.uniform(-0.0254/2,0.0254/2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.arange(30).reshape(3, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.transpose(x_test, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray\n",
      "  Downloading ray-1.9.2-cp37-cp37m-macosx_10_15_intel.whl (58.9 MB)\n",
      "     |████████████████████████████████| 58.9 MB 1.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (1.18.5)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (1.0.3)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (1.40.0)\n",
      "Requirement already satisfied: attrs in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (19.3.0)\n",
      "Requirement already satisfied: jsonschema in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (3.19.1)\n",
      "Requirement already satisfied: filelock in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (3.0.12)\n",
      "Requirement already satisfied: click>=7.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (7.0)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.1-py3-none-any.whl (173 kB)\n",
      "     |████████████████████████████████| 173 kB 4.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray) (5.3)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
      "Collecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=20.4 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from redis>=3.5.0->ray) (21.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from redis>=3.5.0->ray) (4.8.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray) (46.0.0.post20200309)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from deprecated>=1.2.3->redis>=3.5.0->ray) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (4.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (2.2.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.4->redis>=3.5.0->ray) (2.4.6)\n",
      "Installing collected packages: deprecated, redis, ray\n",
      "Successfully installed deprecated-1.2.13 ray-1.9.2 redis-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[tune] in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (1.9.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.0.3)\n",
      "Requirement already satisfied: pyyaml in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (5.3)\n",
      "Requirement already satisfied: filelock in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.0.12)\n",
      "Requirement already satisfied: redis>=3.5.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (4.1.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (7.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.19.1)\n",
      "Requirement already satisfied: jsonschema in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.2.0)\n",
      "Requirement already satisfied: attrs in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (19.3.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.18.5)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.40.0)\n",
      "Requirement already satisfied: pandas in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.3.4)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (2.4)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: requests in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from ray[tune]) (2.22.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from grpcio>=1.28.1->ray[tune]) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from redis>=3.5.0->ray[tune]) (4.8.2)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
      "Requirement already satisfied: packaging>=20.4 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from redis>=3.5.0->ray[tune]) (21.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[tune]) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[tune]) (46.0.0.post20200309)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from pandas->ray[tune]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from pandas->ray[tune]) (2019.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from requests->ray[tune]) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from requests->ray[tune]) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from requests->ray[tune]) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from requests->ray[tune]) (3.0.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.12.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (4.0.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (2.4.6)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.9\n"
     ]
    }
   ],
   "source": [
    "!pip install ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runner import Runner\n",
    "from common.arguments import get_args\n",
    "from common.utils import make_env\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import gym\n",
    "import gym_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('grid-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable(config):\n",
    "    args = get_args()\n",
    "    args.n_players = 8\n",
    "    args.n_agents = 8  \n",
    "    args.obs_shape = [80]*8\n",
    "    args.action_shape = [4]*8\n",
    "    args.high_action = 2\n",
    "    args.low_action = -2\n",
    "    runner = Runner(args, env)\n",
    "    if args.evaluate:\n",
    "        returns = runner.evaluate()\n",
    "        print('Average returns is', returns)\n",
    "    else:\n",
    "        runner.run()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ray.cloudpickle.dumps(<class 'ray.tune.function_runner.wrap_function.<locals>.ImplicitFunc'>) failed.\nTo check which non-serializable variables are captured in scope, re-run the ray script with 'RAY_PICKLE_VERBOSE_DEBUG=1'. Other options: \n-Try reproducing the issue by calling `pickle.dumps(trainable)`. \n-If the error is typing-related, try removing the type annotations and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b60eee8071ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresources_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0mexport_formats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_formats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mmax_failures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_failures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 restore=restore)\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ignoring some parameters passed into tune.run.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ray/tune/experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, run, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, sync_config, trial_name_creator, trial_dirname_creator, log_to_file, checkpoint_freq, checkpoint_at_end, keep_checkpoints_num, checkpoint_score_attr, export_formats, max_failures, restore)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;34m\"checkpointable function. You can specify checkpoints \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \"within your trainable function.\")\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_identifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_identifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ray/tune/experiment.py\u001b[0m in \u001b[0;36mregister_if_needed\u001b[0;34m(cls, run_object)\u001b[0m\n\u001b[1;32m    263\u001b[0m                              \u001b[0;34m\"\\n-If the error is typing-related, try removing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                              \"the type annotations and try again.\")\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_msg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ray.cloudpickle.dumps(<class 'ray.tune.function_runner.wrap_function.<locals>.ImplicitFunc'>) failed.\nTo check which non-serializable variables are captured in scope, re-run the ray script with 'RAY_PICKLE_VERBOSE_DEBUG=1'. Other options: \n-Try reproducing the issue by calling `pickle.dumps(trainable)`. \n-If the error is typing-related, try removing the type annotations and try again."
     ]
    }
   ],
   "source": [
    "tune.run(trainable, config = {}, resources_per_trial={\"cpu\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((8,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for i in range(8):\n",
    "    b.append([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,10,2) (8,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ca730b97bf8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,10,2) (8,2) "
     ]
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.transpose(a, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]],\n",
       "\n",
       "       [[-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.],\n",
       "        [-1., -2.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((8,2))\n",
    "b = np.zeros((8,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate((a,a),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: tensorflow: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!tensorflow --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 2.8.0\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages\r\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, protobuf, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, tf-estimator-nightly, typing-extensions, wrapt\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True, reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[-17.05, 25.06, -32.00], [-27.53, 28.07, -12.91]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.  , 40.98], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "loss_fn = nn.CrossEntropyLoss( reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.tensor([[-17.05, 25.06, -32.00], [-27.53, 28.07, -12.91]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.tensor([[0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-62.2792,  -6.2814])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-efd5b51d78bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "loss_f(loss_fn(y_true, y_pred),y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softXEnt (input, target):\n",
    "    logprobs = torch.nn.functional.log_softmax (input, dim = 1)\n",
    "    return  -(target * logprobs).sum(dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000, 40.9800])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softXEnt(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48240682 -2.27331083  0.99086933  0.53409297]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "logit = np.random.normal(0,1,(4))\n",
    "\n",
    "#logit = tf.random.normal([4,1], 0, 1, tf.float32)\n",
    "print(logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = logit* 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Temp = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "def tf_dis(logit,Temp):\n",
    "    logit, logit_aug = tf.split(logit, 2, 0)\n",
    "\n",
    "    logit_true = tf.nn.softmax(logit/Temp)\n",
    "    logit_aug = tf.nn.softmax(logit_aug/Temp)\n",
    "\n",
    "    logit_true += 1.0e-9\n",
    "    logit_aug += 1.0e-9\n",
    "\n",
    "    logit_true = tf.clip_by_value(logit_true, 1e-9, 1.0, name=None)\n",
    "    logit_aug = tf.clip_by_value(logit_aug, 1e-9, 1.0, name=None)\n",
    "\n",
    "    logit_true = tfp.distributions.Categorical(probs=logit_true)\n",
    "    logit_aug = tfp.distributions.Categorical(probs=logit_aug)\n",
    "\n",
    "    distillation_loss = tfp.distributions.kl_divergence(logit_true,logit_aug,allow_nan_stats= False)\n",
    "    \n",
    "    return distillation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.3147210296813399>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dis(logit, Temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "def torch_dis(logit,temp):\n",
    "    \n",
    "    logit_, logit_aug = torch.tensor_split(logit,2,0) \n",
    "    logit_temp = logit_/temp\n",
    "    logit_aug_temp = logit_aug/temp\n",
    "    logit_true = nn.functional.softmax(logit_temp, dim=0)\n",
    "    logit_aug = nn.functional.softmax(logit_aug_temp, dim=0)\n",
    "\n",
    "    logit_true = logit_true + 1.0e-9\n",
    "    logit_aug = logit_aug + 1.0e-9\n",
    "    lower = torch.tensor(1e-9)\n",
    "    upper = torch.tensor(1.0)\n",
    "    logit_true = torch.clamp(logit_true, min=lower, max=upper)\n",
    "    logit_aug = torch.clamp(logit_aug, min=lower, max=upper)\n",
    "\n",
    "    logit_true = torch.distributions.categorical.Categorical(probs=logit_true)\n",
    "    logit_aug = torch.distributions.categorical.Categorical(probs=logit_aug)\n",
    "\n",
    "    #kl_loss = nn.KLDivLoss()\n",
    "        \n",
    "    #distillation_loss = kl_loss(logit_true,logit_aug)\n",
    "    distillation_loss = torch.distributions.kl.kl_divergence(logit_true,logit_aug)\n",
    "    \n",
    "    return distillation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amoghraut/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3147, dtype=torch.float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = torch.tensor(logit)\n",
    "torch_dis(logit, Temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.6582, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "normal_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "labels = [[0.0,1.0,0.0,0.0]]\n",
    "\n",
    "normal_loss = normal_loss_fn(torch.unsqueeze(logit,0),torch.tensor(labels))\n",
    "print(normal_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    " loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction= tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tf = tf.one_hot([0,1,0,0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_loss = loss_fn([0.0,1.0,0.0,0.0], logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=32.65823745727539>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def pairwise_distance_torch(embeddings, device):\n",
    "    \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
    "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
    "    Args:\n",
    "      embeddings: 2-D Tensor of size [number of data, feature dimension].\n",
    "    Returns:\n",
    "      pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
    "    \"\"\"\n",
    "\n",
    "    # pairwise distance matrix with precise embeddings\n",
    "    precise_embeddings = embeddings.to(dtype=torch.float32)\n",
    "    #precise_embeddings = torch.unsqueeze(precise_embeddings, 0)\n",
    "    c1 = torch.pow(precise_embeddings, 2).sum(axis=-1)\n",
    "   \n",
    "    #print(precise_embeddings.shape)\n",
    "    c2 = torch.pow(precise_embeddings.transpose(0, 1), 2).sum(axis=0)\n",
    "    c3 = precise_embeddings @ precise_embeddings.transpose(0, 1)\n",
    "\n",
    "    c1 = c1.reshape((c1.shape[0], 1))\n",
    "    c2 = c2.reshape((1, c2.shape[0]))\n",
    "    c12 = c1 + c2\n",
    "    pairwise_distances_squared = c12 - 2.0 * c3\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = torch.max(pairwise_distances_squared, torch.tensor([0.]).to(device))\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = pairwise_distances_squared.clone()\n",
    "    error_mask[error_mask > 0.0] = 1.\n",
    "    error_mask[error_mask <= 0.0] = 0.\n",
    "\n",
    "    pairwise_distances = torch.mul(pairwise_distances_squared, error_mask)\n",
    "\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = torch.ones((pairwise_distances.shape[0], pairwise_distances.shape[1])) - torch.diag(torch.ones(pairwise_distances.shape[0]))\n",
    "    pairwise_distances = torch.mul(pairwise_distances.to(device), mask_offdiagonals.to(device))\n",
    "    return pairwise_distances\n",
    "\n",
    "def TripletSemiHardLoss(y_true, y_pred, device, margin=1.0):\n",
    "    \"\"\"Computes the triplet loss_functions with semi-hard negative mining.\n",
    "       The loss_functions encourages the positive distances (between a pair of embeddings\n",
    "       with the same labels) to be smaller than the minimum negative distance\n",
    "       among which are at least greater than the positive distance plus the\n",
    "       margin constant (called semi-hard negative) in the mini-batch.\n",
    "       If no such negative exists, uses the largest negative distance instead.\n",
    "       See: https://arxiv.org/abs/1503.03832.\n",
    "       We expect labels `y_true` to be provided as 1-D integer `Tensor` with shape\n",
    "       [batch_size] of multi-class integer labels. And embeddings `y_pred` must be\n",
    "       2-D float `Tensor` of l2 normalized embedding vectors.\n",
    "       Args:\n",
    "         margin: Float, margin term in the loss_functions definition. Default value is 1.0.\n",
    "         name: Optional name for the op.\n",
    "       \"\"\"\n",
    "\n",
    "    labels, embeddings = y_true, y_pred\n",
    "\n",
    "    \n",
    "\n",
    "    # Reshape label tensor to [batch_size, 1].\n",
    "    lshape = labels.shape\n",
    "    labels = torch.reshape(labels, [lshape[0], 1])\n",
    "    \n",
    "\n",
    "    pdist_matrix = pairwise_distance_torch(embeddings, device)\n",
    "    \n",
    "\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = torch.eq(labels, labels.transpose(0, 1))\n",
    "    \n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = adjacency.logical_not()\n",
    "    \n",
    "    batch_size = labels.shape[0]\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = pdist_matrix.repeat(batch_size, 1)\n",
    "    \n",
    "    adjacency_not_tile = adjacency_not.repeat(batch_size, 1)\n",
    "    \n",
    "\n",
    "    transpose_reshape = pdist_matrix.transpose(0, 1).reshape(-1, 1)\n",
    "    \n",
    "    greater = pdist_matrix_tile > transpose_reshape\n",
    "\n",
    "    mask = adjacency_not_tile & greater\n",
    "\n",
    "    # final mask\n",
    "    mask_step = mask.to(dtype=torch.float32)\n",
    "    mask_step = mask_step.sum(axis=1)\n",
    "    mask_step = mask_step > 0.0\n",
    "    mask_final = mask_step.reshape(batch_size, batch_size)\n",
    "    mask_final = mask_final.transpose(0, 1)\n",
    "\n",
    "    adjacency_not = adjacency_not.to(dtype=torch.float32)\n",
    "    mask = mask.to(dtype=torch.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    axis_maximums = torch.max(pdist_matrix_tile, dim=1, keepdim=True)\n",
    "    masked_minimums = torch.min(torch.mul(pdist_matrix_tile - axis_maximums[0], mask), dim=1, keepdim=True)[0] + axis_maximums[0]\n",
    "    negatives_outside = masked_minimums.reshape([batch_size, batch_size])\n",
    "    negatives_outside = negatives_outside.transpose(0, 1)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    axis_minimums = torch.min(pdist_matrix, dim=1, keepdim=True)\n",
    "    masked_maximums = torch.max(torch.mul(pdist_matrix - axis_minimums[0], adjacency_not), dim=1, keepdim=True)[0] + axis_minimums[0]\n",
    "    negatives_inside = masked_maximums.repeat(1, batch_size)\n",
    "\n",
    "    semi_hard_negatives = torch.where(mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = margin + pdist_matrix - semi_hard_negatives\n",
    "\n",
    "    mask_positives = adjacency.to(dtype=torch.float32) - torch.diag(torch.ones(batch_size)).to(device)\n",
    "    num_positives = mask_positives.sum()\n",
    "\n",
    "    triplet_loss = (torch.max(torch.mul(loss_mat, mask_positives), torch.tensor([0.]).to(device))).sum() / num_positives\n",
    "    triplet_loss = triplet_loss.to(dtype=embeddings.dtype)\n",
    "    return triplet_loss\n",
    "\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input, target, **kwargs):\n",
    "        return TripletSemiHardLoss(target, input, self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "\n",
    "def pairwise_distance(feature, squared=False):\n",
    "    \n",
    "    pairwise_distances_squared = math_ops.add(\n",
    "      math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
    "      math_ops.reduce_sum(\n",
    "          math_ops.square(array_ops.transpose(feature)),\n",
    "          axis=[0],\n",
    "          keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
    "                                                  array_ops.transpose(feature))\n",
    "\n",
    "  # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
    "  # Get the mask where the zero distances are at.\n",
    "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "  # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = math_ops.sqrt(\n",
    "            pairwise_distances_squared + math_ops.to_float(error_mask) * 1e-16)\n",
    "\n",
    "  # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = math_ops.multiply(\n",
    "        pairwise_distances, math_ops.to_float(math_ops.logical_not(error_mask)))\n",
    "\n",
    "    num_data = array_ops.shape(feature)[0]\n",
    "  # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
    "      array_ops.ones([num_data]))\n",
    "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
    "    return pairwise_distances\n",
    "\n",
    "\n",
    "\n",
    "def masked_minimum_idx(data, mask, dim=1):\n",
    "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
    "\n",
    "    masked_minimums_idx = math_ops.argmin(\n",
    "        math_ops.multiply(data - axis_maximums, mask), dim)\n",
    "    return masked_minimums_idx\n",
    "def masked_maximum_idx(data, mask, dim=1):\n",
    "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
    "\n",
    "    masked_maximums_idx = math_ops.argmax(\n",
    "        math_ops.multiply(data - axis_minimums, mask), dim)\n",
    "    return masked_maximums_idx\n",
    "\n",
    "def masked_maximum(data, mask, dim=1):\n",
    "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = math_ops.reduce_max(\n",
    "        math_ops.multiply(data - axis_minimums, mask), dim,\n",
    "        keepdims=True) + axis_minimums\n",
    "    return masked_maximums\n",
    "\n",
    "\n",
    "def masked_minimum(data, mask, dim=1):\n",
    "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = math_ops.reduce_min(\n",
    "        math_ops.multiply(data - axis_maximums, mask), dim,\n",
    "        keepdims=True) + axis_maximums\n",
    "    return masked_minimums\n",
    "\n",
    "\n",
    "def triplet_semihard_loss_tf(labels, embeddings, margin=1.0):\n",
    "\n",
    "    \n",
    "    lshape = array_ops.shape(labels)\n",
    "    assert lshape.shape == 1\n",
    "    labels = array_ops.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=True)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    batch_size = array_ops.size(labels)\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    triplet_loss = math_ops.truediv(\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.maximum(\n",
    "                math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives,\n",
    "        name='triplet_semihard_loss')\n",
    "\n",
    "\n",
    "    return triplet_loss, loss_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_semihard_loss_mine(labels, embeddings, margin=1.0, background=0,log_var=None):\n",
    "    \n",
    "    \n",
    "    lshape = array_ops.shape(labels)\n",
    "    \n",
    "    assert lshape.shape == 1\n",
    "    labels = array_ops.reshape(labels, [lshape[0], 1])\n",
    "\n",
    "  # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=True)\n",
    "  # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "  # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    batch_size = array_ops.size(labels)\n",
    "\n",
    "  # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "  # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "  # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "\n",
    "    negatives_outside_idx = array_ops.reshape(masked_minimum_idx(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside_idx = array_ops.transpose(negatives_outside_idx)\n",
    "    negatives_inside_idx = array_ops.tile(masked_maximum_idx(pdist_matrix, adjacency_not)[:, tf.newaxis], [1, batch_size])\n",
    "\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "    semi_hard_negatives_idx = array_ops.where(\n",
    "        mask_final, negatives_outside_idx, negatives_inside_idx)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "            array_ops.ones([batch_size]))\n",
    "\n",
    "  # mask for foreground events\n",
    "    mask_foreground = array_ops.tile(\n",
    "            math_ops.not_equal(\n",
    "                labels, background), [1, batch_size])\n",
    "    mask_positives = math_ops.multiply(\n",
    "            mask_positives, math_ops.cast(\n",
    "                mask_foreground, dtype=dtypes.float32))\n",
    "\n",
    "  # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "  #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    prefix = 1\n",
    "    suffix = 0\n",
    "    verbose = False\n",
    "    if log_var is not None:\n",
    "\n",
    "      # positive_idx = tf.argmax(furthest_dist, axis=1)\n",
    "      # negative_idx = tf.argmin(dists + 1e5 * tf.cast(same_identity_mask, tf.float32), axis=1)\n",
    "\n",
    "        if verbose:\n",
    "            log_var = tf.Print(log_var, [log_var], 'log_var ', summarize=100)\n",
    "\n",
    "        anchor_log_var = array_ops.tile(log_var, [1, batch_size])\n",
    "        positive_log_var = array_ops.tile(log_var, [batch_size, 1])\n",
    "\n",
    "        if verbose:\n",
    "            anchor_log_var = tf.Print(anchor_log_var, [anchor_log_var], 'anchor_log_var ', summarize=100)\n",
    "            positive_log_var = tf.Print(positive_log_var, [positive_log_var], 'positive_log_var ', summarize=100)\n",
    "\n",
    "        s_anchor = tf.boolean_mask(anchor_log_var, tf.cast(mask_positives, tf.bool))\n",
    "        s_positive = tf.boolean_mask(positive_log_var, tf.cast(mask_positives, tf.bool))\n",
    "        negative_idx = tf.boolean_mask(semi_hard_negatives_idx, tf.cast(mask_positives, tf.bool))\n",
    "\n",
    "        if verbose:\n",
    "            negative_idx = tf.Print(negative_idx, [negative_idx], 'negative_idx ', summarize=100)\n",
    "\n",
    "        s_negative = tf.gather_nd(log_var, negative_idx[:, tf.newaxis])\n",
    "\n",
    "        if verbose:\n",
    "            s_anchor = tf.Print(s_anchor, [s_anchor], 's_anchor ', summarize=100)\n",
    "            s_positive = tf.Print(s_positive, [s_positive], 's_positive ', summarize=100)\n",
    "            s_negative = tf.Print(s_negative, [s_negative], 's_negative ', summarize=100)\n",
    "        print('Using Log Var')\n",
    "\n",
    "        prefix = 0.5 * (tf.exp(-s_anchor) + tf.exp(-s_positive) + tf.exp(-s_negative))\n",
    "        suffix = 0.5 * (s_anchor + s_positive + s_negative)\n",
    "\n",
    "      # log_var = tf.nn.relu(log_var)\n",
    "\n",
    "      # s_anchor = log_var\n",
    "      # s_positive = tf.gather_nd(log_var, positive_idx[:, tf.newaxis])\n",
    "      # s_negative = tf.gather_nd(log_var, negative_idx[:, tf.newaxis])\n",
    "\n",
    "      # furthest_positive = furthest_positive  # * (tf.exp(-s_anchor) + tf.exp(-s_positive) + tf.exp(-s_negative)) #+ 0.5 * (s_anchor + s_positive + s_negative)\n",
    "      # closest_negative = closest_negative  # * (tf.exp(-s_anchor) + tf.exp(-s_positive) + tf.exp(-s_negative))\n",
    "\n",
    "      # prefix = 0.5 * (tf.exp(-s_anchor) + tf.exp(-s_positive) + tf.exp(-s_negative))\n",
    "      # suffix = 0.5 * (s_anchor + s_positive + s_negative)\n",
    "\n",
    "        print('prefix add log ****')\n",
    "    else:\n",
    "        print('Not ** Using Log Var')\n",
    "\n",
    "  #triplet_loss = prefix * tf.nn.softplus(tf.boolean_mask(loss_mat, tf.cast(mask_positives, tf.bool))) + suffix\n",
    "    triplet_loss =  prefix * math_ops.maximum(tf.boolean_mask(loss_mat, mask_positives), 0.0) + suffix\n",
    "  # triplet_loss = math_ops.truediv(\n",
    "  #     math_ops.reduce_sum(\n",
    "  #         math_ops.maximum(\n",
    "  #             math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "  #     num_positives,\n",
    "  #     name='triplet_semihard_loss')\n",
    "\n",
    "  # keep track of active count for analysis\n",
    "    active_count = math_ops.truediv(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.multiply(math_ops.cast(\n",
    "                    mask_final,dtype=dtypes.float32), mask_positives)),\n",
    "            num_positives,\n",
    "            name='active_count')\n",
    "\n",
    "    return triplet_loss, active_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/amoghraut/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0c9ba86a2846519fe47bfed77a5633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "base_model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
